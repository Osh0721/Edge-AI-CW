{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with persons and their respective embeddings vectors:\n",
      "  Person                                         Embeddings\n",
      "0  Nadun  [[-0.0019360791, 0.0008485403, -0.04033895, 0....\n",
      "1  Oshan  [[-0.02711575, 0.04439154, -0.03770283, 0.0751...\n",
      "2   Maxi  [[-0.01844999, 0.06442268, -0.014021691, 0.080...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import pandas as pd  # Import pandas for DataFrame functionality\n",
    "\n",
    "def is_image_file(filename):\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
    "    return any(filename.lower().endswith(ext) for ext in valid_extensions)\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((160, 160))\n",
    "    image = np.asarray(image)\n",
    "    image = image.astype('float32')\n",
    "    mean, std = image.mean(), image.std()\n",
    "    image = (image - mean) / std\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def load_pb_model(model_filepath):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with open(model_filepath, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "def generate_embeddings_dataframe(graph, dataset_path):\n",
    "    person_embeddings = {}\n",
    "    with tf.compat.v1.Session(graph=graph) as sess:\n",
    "        for person_name in os.listdir(dataset_path):\n",
    "            person_path = os.path.join(dataset_path, person_name)\n",
    "            if os.path.isdir(person_path):\n",
    "                person_embeddings[person_name] = []\n",
    "                for image_name in os.listdir(person_path):\n",
    "                    if not is_image_file(image_name):\n",
    "                        continue  # Skip files that are not images\n",
    "                    image_path = os.path.join(person_path, image_name)\n",
    "                    try:\n",
    "                        image = load_image(image_path)\n",
    "                    except UnidentifiedImageError:\n",
    "                        print(f\"Skipping file (not an image): {image_path}\")\n",
    "                        continue\n",
    "                    images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "                    embeddings_tensor = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "                    phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "                    feed_dict = {images_placeholder: image, phase_train_placeholder: False}\n",
    "                    embedding = sess.run(embeddings_tensor, feed_dict=feed_dict).flatten()\n",
    "                    person_embeddings[person_name].append(embedding)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    # Each row contains the person's name and a list of their embeddings\n",
    "    df = pd.DataFrame(list(person_embeddings.items()), columns=['Person', 'Embeddings'])\n",
    "    return df\n",
    "\n",
    "model_filepath = '20180402-114759/20180402-114759.pb'\n",
    "graph = load_pb_model(model_filepath)\n",
    "dataset_path = 'database'\n",
    "embeddings_df = generate_embeddings_dataframe(graph, dataset_path)\n",
    "\n",
    "print(\"DataFrame with persons and their respective embeddings vectors:\")\n",
    "print(embeddings_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted person: Maxi, Best Similarity: 0.68\n",
      "Similarity Scores with all individuals:\n",
      "Nadun: 0.29\n",
      "Oshan: 0.66\n",
      "Maxi: 0.68\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_with_similarity_scores(graph, image_path, embeddings_df, threshold=0.5):\n",
    "    new_embedding = get_embedding(graph, image_path)\n",
    "    similarity_scores = {}\n",
    "\n",
    "    for _, row in embeddings_df.iterrows():\n",
    "        person = row['Person']\n",
    "        person_scores = []\n",
    "        for embedding in row['Embeddings']:\n",
    "            distance = cosine(new_embedding, embedding)\n",
    "            similarity = 1 - distance  # Convert distance to similarity\n",
    "            person_scores.append(similarity)\n",
    "        # Average similarity for this person\n",
    "        average_similarity = np.mean(person_scores)\n",
    "        similarity_scores[person] = average_similarity\n",
    "    \n",
    "    # Finding the person with the highest similarity score\n",
    "    best_match = max(similarity_scores, key=similarity_scores.get)\n",
    "    best_similarity_score = similarity_scores[best_match]\n",
    "\n",
    "    if best_similarity_score < threshold:\n",
    "        return \"Not in database\", None, similarity_scores\n",
    "    \n",
    "    return best_match, best_similarity_score, similarity_scores\n",
    "\n",
    "# Example usage\n",
    "test_image_path = 'test/person/1679079149243.jpeg'  # Replace with your actual image path\n",
    "predicted_person, best_similarity, all_similarity_scores = predict_with_similarity_scores(graph, test_image_path, embeddings_df)\n",
    "\n",
    "if predicted_person != \"Not in database\":\n",
    "    print(f\"Predicted person: {predicted_person}, Best Similarity: {best_similarity:.2f}\")\n",
    "    print(\"Similarity Scores with all individuals:\")\n",
    "    for person, score in all_similarity_scores.items():\n",
    "        print(f\"{person}: {score:.2f}\")\n",
    "else:\n",
    "    print(predicted_person)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
