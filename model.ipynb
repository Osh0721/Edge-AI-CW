{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((160, 160))  # Resize to the input size expected by FaceNet\n",
    "    image = np.asarray(image)\n",
    "    image = image.astype('float32')\n",
    "    mean, std = image.mean(), image.std()\n",
    "    image = (image - mean) / std\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def load_pb_model(model_filepath):\n",
    "    # Load TensorFlow Graph from .pb file\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "    with open(model_filepath, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    \n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "def generate_embeddings(graph, dataset_path):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with tf.compat.v1.Session(graph=graph) as sess:\n",
    "        for person_name in os.listdir(dataset_path):\n",
    "            person_path = os.path.join(dataset_path, person_name)\n",
    "            if os.path.isdir(person_path):  # Add this check here\n",
    "                for image_name in os.listdir(person_path):\n",
    "                    image_path = os.path.join(person_path, image_name)\n",
    "                    if os.path.isfile(image_path):  # Optionally, ensure this is a file\n",
    "                        image = load_image(image_path)\n",
    "                        \n",
    "                        # Fetch the tensors\n",
    "                        images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "                        embeddings_tensor = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "                        phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "                        feed_dict = {images_placeholder: image, phase_train_placeholder: False}\n",
    "                        embedding = sess.run(embeddings_tensor, feed_dict=feed_dict)\n",
    "                        \n",
    "                        embeddings.append(embedding)\n",
    "                        labels.append(person_name)\n",
    "    embeddings = np.asarray(embeddings).reshape(len(embeddings), -1)  # Reshape to (num_samples, embedding_size)\n",
    "    labels = np.asarray(labels)\n",
    "    return embeddings, labels\n",
    "\n",
    "\n",
    "model_filepath = '20180402-114759/20180402-114759.pb'  # Update this path to your .pb model file\n",
    "graph = load_pb_model(model_filepath)\n",
    "dataset_path = 'dataset'  # Update this path to your dataset\n",
    "embeddings, labels = generate_embeddings(graph, dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 5750/5750 [00:26<00:00, 219.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and preprocessed 13233 images.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_image(image_path, target_size=(160, 160)):\n",
    "    \"\"\"Load an image file, resize it to target size, and normalize it.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    image_array = np.array(image)\n",
    "    # Normalize the image\n",
    "    image_array = image_array.astype('float32')\n",
    "    mean, std = image_array.mean(), image_array.std()\n",
    "    image_array = (image_array - mean) / std\n",
    "    return image_array\n",
    "\n",
    "def load_dataset(dataset_path, target_size=(160, 160)):\n",
    "    \"\"\"Load and preprocess the entire dataset.\"\"\"\n",
    "    X, y = [], []\n",
    "    # Walk through the person directories and list their images\n",
    "    for person_name in tqdm(os.listdir(dataset_path), desc=\"Processing\"):\n",
    "        person_path = os.path.join(dataset_path, person_name)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue  # Skip non-directory files\n",
    "        for image_name in os.listdir(person_path):\n",
    "            image_path = os.path.join(person_path, image_name)\n",
    "            if not os.path.isfile(image_path) or not image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue  # Skip non-image files\n",
    "            image_array = preprocess_image(image_path, target_size)\n",
    "            X.append(image_array)\n",
    "            y.append(person_name)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Path to your dataset\n",
    "dataset_path = 'dataset'\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "X, y = load_dataset(dataset_path)\n",
    "\n",
    "print(f\"Loaded and preprocessed {len(X)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.3999 - accuracy: 0.0000e+00 - val_loss: 1.3074 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3325 - accuracy: 0.6667 - val_loss: 1.3129 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3047 - accuracy: 0.6667 - val_loss: 1.3178 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2689 - accuracy: 0.6667 - val_loss: 1.3207 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1867 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1806 - accuracy: 1.0000 - val_loss: 1.3265 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1034 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0151 - accuracy: 1.0000 - val_loss: 1.3341 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0527 - accuracy: 1.0000 - val_loss: 1.3383 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1140 - accuracy: 1.0000 - val_loss: 1.3420 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the new model architecture\n",
    "embedding_input_size = embeddings.shape[1]  # This should match the size of your FaceNet embeddings\n",
    "input_layer = Input(shape=(embedding_input_size,))\n",
    "x = Dense(128, activation='relu')(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(len(np.unique(labels_encoded)), activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "classifier_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = classifier_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3420 - accuracy: 0.0000e+00\n",
      "Test Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = classifier_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_save_path = 'path_to_save_your_model/facenet_classifier.h5'\n",
    "classifier_model.save(model_save_path)\n",
    "\n",
    "# To save just the weights\n",
    "weights_save_path = 'path_to_save_your_model/facenet_classifier_weights.h5'\n",
    "classifier_model.save_weights(weights_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_person(image_path, facenet_model, classifier_model, label_encoder):\n",
    "    # Load and preprocess the image\n",
    "    image = load_image(image_path)  # This should be the same function you used before\n",
    "\n",
    "    # Generate embedding using FaceNet\n",
    "    with tf.compat.v1.Session(graph=facenet_model) as sess:\n",
    "        images_placeholder = facenet_model.get_tensor_by_name(\"input:0\")\n",
    "        embeddings_tensor = facenet_model.get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = facenet_model.get_tensor_by_name(\"phase_train:0\")\n",
    "        \n",
    "        feed_dict = {images_placeholder: image, phase_train_placeholder: False}\n",
    "        embedding = sess.run(embeddings_tensor, feed_dict=feed_dict)\n",
    "\n",
    "    embedding = np.reshape(embedding, (1, -1))  # Reshape the embedding to match the classifier's input expectation\n",
    "    \n",
    "    # Predict using the classifier model\n",
    "    prediction = classifier_model.predict(embedding)\n",
    "    predicted_label_idx = np.argmax(prediction, axis=1)\n",
    "    predicted_label = label_encoder.inverse_transform(predicted_label_idx)\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Example usage\n",
    "image_path = 'path_to_your_new_image.jpg'\n",
    "facenet_graph = load_pb_model('20180402-114759/20180402-114759.pb')  # Load the FaceNet model as before\n",
    "predicted_person = predict_person(image_path, facenet_graph, classifier_model, label_encoder)\n",
    "print(f\"Predicted person: {predicted_person}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
