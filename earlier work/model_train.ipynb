{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def is_image_file(filename):\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
    "    return any(filename.lower().endswith(ext) for ext in valid_extensions)\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((160, 160))\n",
    "    image = np.asarray(image)\n",
    "    image = image.astype('float32')\n",
    "    mean, std = image.mean(), image.std()\n",
    "    image = (image - mean) / std\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def load_pb_model(model_filepath):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with open(model_filepath, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "def generate_embeddings(graph, dataset_path):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with tf.compat.v1.Session(graph=graph) as sess:\n",
    "        for person_name in os.listdir(dataset_path):\n",
    "            person_path = os.path.join(dataset_path, person_name)\n",
    "            if os.path.isdir(person_path):\n",
    "                for image_name in os.listdir(person_path):\n",
    "                    if not is_image_file(image_name):\n",
    "                        continue  # Skip files that are not images\n",
    "                    image_path = os.path.join(person_path, image_name)\n",
    "                    try:\n",
    "                        image = load_image(image_path)\n",
    "                    except UnidentifiedImageError:\n",
    "                        print(f\"Skipping file (not an image): {image_path}\")\n",
    "                        continue  # Skip files that cannot be identified as images\n",
    "                    # Fetch the tensors\n",
    "                    images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "                    embeddings_tensor = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "                    phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "                    feed_dict = {images_placeholder: image, phase_train_placeholder: False}\n",
    "                    embedding = sess.run(embeddings_tensor, feed_dict=feed_dict)\n",
    "                    embeddings.append(embedding)\n",
    "                    labels.append(person_name)\n",
    "    embeddings = np.asarray(embeddings).reshape(len(embeddings), -1)\n",
    "    labels = np.asarray(labels)\n",
    "    return embeddings, labels\n",
    "\n",
    "model_filepath = '20180402-114759/20180402-114759.pb'\n",
    "graph = load_pb_model(model_filepath)\n",
    "dataset_path = 'dataset'\n",
    "embeddings, labels = generate_embeddings(graph, dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 4/4 [00:00<00:00, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and preprocessed 6 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def preprocess_image(image_path, target_size=(160, 160)):\n",
    "#     \"\"\"Load an image file, resize it to target size, and normalize it.\"\"\"\n",
    "#     image = Image.open(image_path)\n",
    "#     image = image.resize(target_size)\n",
    "#     image_array = np.array(image)\n",
    "#     # Normalize the image\n",
    "#     image_array = image_array.astype('float32')\n",
    "#     mean, std = image_array.mean(), image_array.std()\n",
    "#     image_array = (image_array - mean) / std\n",
    "#     return image_array\n",
    "\n",
    "# def load_dataset(dataset_path, target_size=(160, 160)):\n",
    "#     \"\"\"Load and preprocess the entire dataset.\"\"\"\n",
    "#     X, y = [], []\n",
    "#     # Walk through the person directories and list their images\n",
    "#     for person_name in tqdm(os.listdir(dataset_path), desc=\"Processing\"):\n",
    "#         person_path = os.path.join(dataset_path, person_name)\n",
    "#         if not os.path.isdir(person_path):\n",
    "#             continue  # Skip non-directory files\n",
    "#         for image_name in os.listdir(person_path):\n",
    "#             image_path = os.path.join(person_path, image_name)\n",
    "#             if not os.path.isfile(image_path) or not image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                 continue  # Skip non-image files\n",
    "#             image_array = preprocess_image(image_path, target_size)\n",
    "#             X.append(image_array)\n",
    "#             y.append(person_name)\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "# # Path to your dataset\n",
    "# dataset_path = 'database'\n",
    "\n",
    "# # Load and preprocess the dataset\n",
    "# X, y = load_dataset(dataset_path)\n",
    "\n",
    "# print(f\"Loaded and preprocessed {len(X)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 7.9495 - accuracy: 0.0499 - val_loss: 7.6188 - val_accuracy: 0.0640\n",
      "Epoch 2/10\n",
      "332/332 [==============================] - 2s 5ms/step - loss: 7.0336 - accuracy: 0.0881 - val_loss: 7.5065 - val_accuracy: 0.1126\n",
      "Epoch 3/10\n",
      "332/332 [==============================] - 2s 5ms/step - loss: 6.5549 - accuracy: 0.1227 - val_loss: 7.4611 - val_accuracy: 0.1434\n",
      "Epoch 4/10\n",
      "332/332 [==============================] - 1s 4ms/step - loss: 6.1129 - accuracy: 0.1536 - val_loss: 7.4626 - val_accuracy: 0.1755\n",
      "Epoch 5/10\n",
      "332/332 [==============================] - 2s 5ms/step - loss: 5.6555 - accuracy: 0.1850 - val_loss: 7.4498 - val_accuracy: 0.2044\n",
      "Epoch 6/10\n",
      "332/332 [==============================] - 2s 5ms/step - loss: 5.1327 - accuracy: 0.2240 - val_loss: 7.4214 - val_accuracy: 0.2361\n",
      "Epoch 7/10\n",
      "332/332 [==============================] - 2s 5ms/step - loss: 4.5943 - accuracy: 0.2670 - val_loss: 7.4284 - val_accuracy: 0.2609\n",
      "Epoch 8/10\n",
      "332/332 [==============================] - 1s 4ms/step - loss: 4.0597 - accuracy: 0.3084 - val_loss: 7.4700 - val_accuracy: 0.2854\n",
      "Epoch 9/10\n",
      "332/332 [==============================] - 2s 5ms/step - loss: 3.5246 - accuracy: 0.3587 - val_loss: 7.5524 - val_accuracy: 0.3012\n",
      "Epoch 10/10\n",
      "332/332 [==============================] - 2s 5ms/step - loss: 3.0299 - accuracy: 0.4048 - val_loss: 7.5860 - val_accuracy: 0.3129\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Assuming `embeddings` and `labels` are available from previous steps\n",
    "# Encode the labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Save the fitted LabelEncoder to a file\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "# Splitting the dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the classifier model\n",
    "def build_classifier_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Building the model\n",
    "num_classes = len(np.unique(labels_encoded))\n",
    "classifier_model = build_classifier_model(X_train.shape[1], num_classes)\n",
    "\n",
    "# Training the model\n",
    "history = classifier_model.fit(X_train, y_train, \n",
    "                               epochs=10, \n",
    "                               validation_data=(X_test, y_test), \n",
    "                               batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 7.5860 - accuracy: 0.3129\n",
      "Test Loss: 7.5860443115234375, Test Accuracy: 0.31287649273872375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "evaluation = classifier_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}')\n",
    "\n",
    "# Save the model and the label encoder for later use\n",
    "classifier_model.save('face_recognition_classifier.h5')\n",
    "# Ensure you also save `label_encoder` using joblib or pickle to decode predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.15961063\n",
      "Predicted person: Hugo_Chavez with confidence: 0.15961062908172607\n",
      "Attendance marked for: Hugo_Chavez\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib  # For loading the label encoder\n",
    "\n",
    "# Function to load the FaceNet model\n",
    "def load_pb_model(model_filepath):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with open(model_filepath, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "# Load your trained classifier model and label encoder\n",
    "classifier_model = load_model('face_recognition_classifier.h5')\n",
    "label_encoder = joblib.load('label_encoder.joblib')\n",
    "\n",
    "# Load the FaceNet model\n",
    "facenet_model = load_pb_model('20180402-114759/20180402-114759.pb')\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((160, 160))  # Resize as per FaceNet's requirements\n",
    "    image = np.asarray(image)\n",
    "    image = image.astype('float32')\n",
    "    mean, std = image.mean(), image.std()\n",
    "    image = (image - mean) / std\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_embedding(model, image):\n",
    "    with tf.compat.v1.Session(graph=model) as sess:\n",
    "        images_placeholder = model.get_tensor_by_name(\"input:0\")\n",
    "        embeddings_tensor = model.get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = model.get_tensor_by_name(\"phase_train:0\")\n",
    "        feed_dict = {images_placeholder: image, phase_train_placeholder: False}\n",
    "        embedding = sess.run(embeddings_tensor, feed_dict=feed_dict)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def predict_identity(image_path, confidence_threshold):\n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    \n",
    "    # Generate embedding\n",
    "    embedding = get_embedding(facenet_model, preprocessed_image)\n",
    "    \n",
    "    # Predict using the classifier model and get confidence scores\n",
    "    prediction_scores = classifier_model.predict(embedding)\n",
    "    confidence = np.max(prediction_scores)\n",
    "    predicted_label_idx = np.argmax(prediction_scores, axis=1)\n",
    "\n",
    "    print(confidence)\n",
    "    \n",
    "    if confidence < confidence_threshold:\n",
    "        print(\"This person does not exist in the database.\")\n",
    "        return None\n",
    "    else:\n",
    "        predicted_label = label_encoder.inverse_transform(predicted_label_idx)\n",
    "        print(f\"Predicted person: {predicted_label[0]} with confidence: {confidence}\")\n",
    "        return predicted_label[0]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'test/person/Kong_Quan_0001.jpg'  # Replace with your image path\n",
    "predicted_person = predict_identity(image_path, confidence_threshold=0.1)  # Adjust threshold as needed\n",
    "\n",
    "if predicted_person:\n",
    "    print(f\"Attendance marked for: {predicted_person}\")\n",
    "else:\n",
    "    print(\"Unable to mark attendance, person not recognized.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
